{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "X9FmZ7IFGXbh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertModel, DistilBertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "12xsM-Y09WeC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0b3de70-da73-4333-c006-34514f89a026"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Triage(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        memo = str(self.data.Memo[index])\n",
        "        memo = \" \".join(memo.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            memo,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.Tags_Encoded[index], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "MFBMIX3cN1pG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 7)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ],
      "metadata": {
        "id": "-cc4non4N9Zx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistillBERTClass()\n",
        "\n",
        "state_dict = torch.load('best_synthetic.pkl')\n",
        "\n",
        "adjusted_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "model.load_state_dict(adjusted_state_dict)\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "MiwBoaeAOE9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "\n",
        "  while True:\n",
        "    df = pd.DataFrame(columns=['Memo', 'Tags'])\n",
        "\n",
        "    print(\"Please enter an example memo for a transaction:\")\n",
        "    memo = input(\"Memo: \")\n",
        "\n",
        "    print(\"Please enter the tag you expect for this memo: \\n\")\n",
        "    print(\"Tags include:  ['Funding', 'Operations', 'Misc', 'Food', 'Equipment', 'Programming', 'Travel']\")\n",
        "    tag = input(\"Tag: \")\n",
        "\n",
        "    new_row = pd.DataFrame({'Memo': [memo], 'Tags': [tag]})\n",
        "    df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    tags = ['Funding', 'Operations', 'Misc', 'Food', 'Equipment', 'Programming', 'Travel']\n",
        "    map = {tag: i for i, tag in enumerate(tags)}\n",
        "\n",
        "    def encode_tags(x):\n",
        "        return map.get(x, -1)\n",
        "\n",
        "    df['Tags_Encoded'] = df['Tags'].apply(lambda x: encode_tags(x))\n",
        "\n",
        "    # print(df.head())\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "    data = Triage(df, tokenizer, max_len=512)\n",
        "    # print(data)\n",
        "\n",
        "    loader_params = {\n",
        "                    'batch_size': 1,\n",
        "                    'shuffle': False,\n",
        "                    'num_workers': 0\n",
        "                  }\n",
        "\n",
        "    loader = DataLoader(data, **loader_params)\n",
        "    # print(loader)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.long)\n",
        "\n",
        "            outputs = model(ids, mask)\n",
        "            _, big_idx = torch.max(outputs, dim=1)\n",
        "\n",
        "            decode_map =  {i: tag for i, tag in enumerate(tags)}\n",
        "            decoded_inputs = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "            predicted_class = decode_map[big_idx[0].item()]\n",
        "            true_class = decode_map[targets[0].item()]\n",
        "\n",
        "            print(f\"\\nInput Text: {decoded_inputs}\")\n",
        "            print(f\"Predicted Class: {predicted_class}, True Class: {true_class}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H7jxjTv2OVPK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict()"
      ],
      "metadata": {
        "id": "I9zcDOJxGafy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wF8LOjaMx8v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}